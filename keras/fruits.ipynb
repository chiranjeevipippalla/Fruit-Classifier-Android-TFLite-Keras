{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apples and Bananas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following model classifies two different fruit categories - Apples and Bananas. Please feel free to change the categories and classify the items/classes of your choice.\n",
    "\n",
    "Please note that the below model works for classifying only two categories. If you want to classify more than two classes, use one hot encoding for the labels and use the loss function as \"categorical_cross_entropy\" and update the number of nodes in the final Dense layer equal to number of classes you want to classify."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is a path to your dataset directory.\n",
    "DATADIR = \"C:/Users/Idea/Desktop/Fruits/datasets\"\n",
    "\n",
    "#Names of the categories the model predicts\n",
    "CATEGORIES = [\"Apples\", \"Bananas\"]\n",
    "\n",
    "#Train the model by inputting the images of size 50X50. It is a choice.\n",
    "IMG_SIZE = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 232/232 [00:04<00:00, 48.15it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 218/218 [00:04<00:00, 48.64it/s]\n"
     ]
    }
   ],
   "source": [
    "training_data = []\n",
    "\n",
    "def create_training_data():\n",
    "    for category in CATEGORIES:\n",
    "        path = os.path.join(DATADIR,category) \n",
    "        class_num = CATEGORIES.index(category) \n",
    "        for img in tqdm(os.listdir(path)):\n",
    "            try:\n",
    "                img_array = cv2.imread(os.path.join(path,img) ,cv2.IMREAD_GRAYSCALE) \n",
    "                new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))  \n",
    "                training_data.append([new_array, class_num]) \n",
    "            except Exception as e:\n",
    "                pass\n",
    "\n",
    "create_training_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shuffle the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "random.shuffle(training_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate attributes/features and decisions/labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "\n",
    "for features,label in training_data:\n",
    "    X.append(features)\n",
    "    y.append(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert the features and labels into numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X).reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalising the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X/255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build your Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 405 samples, validate on 45 samples\n",
      "Epoch 1/5\n",
      "405/405 [==============================] - ETA: 1:17 - loss: 0.6802 - accuracy: 0.62 - ETA: 38s - loss: 1.3041 - accuracy: 0.5781 - ETA: 24s - loss: 1.1620 - accuracy: 0.552 - ETA: 17s - loss: 1.1842 - accuracy: 0.554 - ETA: 12s - loss: 1.0878 - accuracy: 0.581 - ETA: 9s - loss: 1.0339 - accuracy: 0.588 - ETA: 7s - loss: 1.0030 - accuracy: 0.59 - ETA: 5s - loss: 0.9908 - accuracy: 0.59 - ETA: 3s - loss: 0.9535 - accuracy: 0.59 - ETA: 2s - loss: 0.9166 - accuracy: 0.59 - ETA: 1s - loss: 0.8907 - accuracy: 0.59 - ETA: 0s - loss: 0.8753 - accuracy: 0.60 - 10s 25ms/sample - loss: 0.8666 - accuracy: 0.6099 - val_loss: 0.4700 - val_accuracy: 0.7778\n",
      "Epoch 2/5\n",
      "405/405 [==============================] - ETA: 1s - loss: 0.5234 - accuracy: 0.71 - ETA: 1s - loss: 0.4895 - accuracy: 0.75 - ETA: 1s - loss: 0.5129 - accuracy: 0.72 - ETA: 0s - loss: 0.5375 - accuracy: 0.71 - ETA: 0s - loss: 0.5419 - accuracy: 0.70 - ETA: 0s - loss: 0.5250 - accuracy: 0.72 - ETA: 0s - loss: 0.5034 - accuracy: 0.75 - ETA: 0s - loss: 0.4950 - accuracy: 0.75 - ETA: 0s - loss: 0.4933 - accuracy: 0.75 - ETA: 0s - loss: 0.4786 - accuracy: 0.76 - ETA: 0s - loss: 0.4740 - accuracy: 0.76 - ETA: 0s - loss: 0.4601 - accuracy: 0.78 - 1s 4ms/sample - loss: 0.4521 - accuracy: 0.7951 - val_loss: 0.3388 - val_accuracy: 0.8889\n",
      "Epoch 3/5\n",
      "405/405 [==============================] - ETA: 1s - loss: 0.2900 - accuracy: 0.93 - ETA: 1s - loss: 0.3208 - accuracy: 0.89 - ETA: 1s - loss: 0.3055 - accuracy: 0.88 - ETA: 0s - loss: 0.3473 - accuracy: 0.84 - ETA: 0s - loss: 0.3614 - accuracy: 0.82 - ETA: 0s - loss: 0.3526 - accuracy: 0.83 - ETA: 0s - loss: 0.3458 - accuracy: 0.84 - ETA: 0s - loss: 0.3385 - accuracy: 0.84 - ETA: 0s - loss: 0.3524 - accuracy: 0.84 - ETA: 0s - loss: 0.3484 - accuracy: 0.85 - ETA: 0s - loss: 0.3415 - accuracy: 0.85 - ETA: 0s - loss: 0.3465 - accuracy: 0.84 - 1s 4ms/sample - loss: 0.3472 - accuracy: 0.8469 - val_loss: 0.2542 - val_accuracy: 0.9111\n",
      "Epoch 4/5\n",
      "405/405 [==============================] - ETA: 1s - loss: 0.2666 - accuracy: 0.87 - ETA: 1s - loss: 0.2409 - accuracy: 0.93 - ETA: 1s - loss: 0.2502 - accuracy: 0.93 - ETA: 1s - loss: 0.2278 - accuracy: 0.95 - ETA: 0s - loss: 0.2264 - accuracy: 0.95 - ETA: 0s - loss: 0.2326 - accuracy: 0.94 - ETA: 0s - loss: 0.2359 - accuracy: 0.93 - ETA: 0s - loss: 0.2386 - accuracy: 0.93 - ETA: 0s - loss: 0.2470 - accuracy: 0.93 - ETA: 0s - loss: 0.2496 - accuracy: 0.93 - ETA: 0s - loss: 0.2431 - accuracy: 0.93 - ETA: 0s - loss: 0.2433 - accuracy: 0.93 - 2s 4ms/sample - loss: 0.2370 - accuracy: 0.9407 - val_loss: 0.2322 - val_accuracy: 0.8889\n",
      "Epoch 5/5\n",
      "405/405 [==============================] - ETA: 1s - loss: 0.1130 - accuracy: 0.96 - ETA: 1s - loss: 0.1931 - accuracy: 0.93 - ETA: 1s - loss: 0.1656 - accuracy: 0.94 - ETA: 1s - loss: 0.1659 - accuracy: 0.94 - ETA: 0s - loss: 0.1559 - accuracy: 0.95 - ETA: 0s - loss: 0.1701 - accuracy: 0.93 - ETA: 0s - loss: 0.1910 - accuracy: 0.91 - ETA: 0s - loss: 0.2092 - accuracy: 0.90 - ETA: 0s - loss: 0.2276 - accuracy: 0.89 - ETA: 0s - loss: 0.2192 - accuracy: 0.90 - ETA: 0s - loss: 0.2146 - accuracy: 0.90 - ETA: 0s - loss: 0.2319 - accuracy: 0.89 - 1s 4ms/sample - loss: 0.2219 - accuracy: 0.8963 - val_loss: 0.1895 - val_accuracy: 0.9333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2b402937c50>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_model():\n",
    "\n",
    "    model = Sequential()\n",
    "    \n",
    "    #Input Layer\n",
    "    model.add(Conv2D(filters=32, kernel_size=3, padding='same', activation='relu', input_shape=(50,50,1)))\n",
    "    model.add(MaxPooling2D(pool_size=2))\n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    #Layer\n",
    "    Conv2D(filters=64, kernel_size=3, padding='same', activation='relu'),\n",
    "    MaxPooling2D(pool_size=2),\n",
    "    Dropout(0.3),\n",
    "    \n",
    "    #Flattening before the fully-connected network\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    #Final Output Layer\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "  \n",
    "   #Compile the model\n",
    "    model.compile(loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
    "         optimizer=tf.keras.optimizers.Adam(),\n",
    "         metrics=['accuracy'])\n",
    "      \n",
    "    return model\n",
    "\n",
    "\n",
    "model = create_model()\n",
    "\n",
    "\n",
    "model.fit(X, y,\n",
    "          batch_size=32,\n",
    "          epochs=5,\n",
    "          validation_split=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save your trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_file = \"fruits.h5\"\n",
    "tf.keras.models.save_model(model, keras_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert your saved .h5 model file to tflite file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10244700"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tf.keras.models.load_model(\"fruits.h5\")\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "open(\"fruits.tflite\", \"wb\").write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
